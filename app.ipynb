{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33e2c59",
   "metadata": {},
   "source": [
    "# ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0beb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_page():\n",
    "    # ! CSS\n",
    "    apply_custom_css()\n",
    "    st.markdown(\n",
    "      \"\"\"<script>\n",
    "        document.addEventListener('DOMContentLoaded', function() {\n",
    "            // Try to load the logo, if it fails, show fallback text\n",
    "            var logoImg = document.querySelector('.logo-image');\n",
    "            if (logoImg) {\n",
    "                logoImg.onerror = function() {\n",
    "                    var logoContainer = document.querySelector('.logo-container');\n",
    "                    if (logoContainer) {\n",
    "                        logoContainer.innerHTML = '<div style=\"font-size: 40px;\">üöÄ</div>';\n",
    "                    }\n",
    "                };\n",
    "            }\n",
    "        });\n",
    "    </script>\"\"\",unsafe_allow_html=True\n",
    "    )\n",
    "def display_header():\n",
    "    try:\n",
    "        with open(\"image.png\",\"rb\") as img_file:\n",
    "            logo_base64=base64.b64encode(img_file.read()).decode()\n",
    "            logo_html = f'<img src=\"data:image/jpeg;base64,{logo_base64}\" alt=\"RECRUITER Logo\" class=\"logo-image\" style=\"max-height: 100px;\">'\n",
    "\n",
    "    except:\n",
    "        logo_html = '<div style=\"font-size: 50px; text-align: center;\">üöÄ</div>'\n",
    "        \n",
    "    st.markdown(f\"\"\"\n",
    "    <div class=\"main-header\">\n",
    "        <div class=\"header-container\">\n",
    "            <div class=\"logo-container\" style=\"text-align: center; margin-bottom: 20px;\">\n",
    "                {logo_html}\n",
    "            </div>\n",
    "            <div class=\"title-container\" style=\"text-align: center;\">\n",
    "                <h1>Recruiter Recruitment Agent</h1>\n",
    "                <p>Smart Resume Analysis & Interview Preparation System</p>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "def apply_custom_css(accent_color=\"#d32f2f\"):\n",
    "    st.markdown(f\"\"\"\n",
    "    <style>\n",
    "        /* Main container */\n",
    "        .main {{\n",
    "            background-color: #000000 !important;\n",
    "            color: white !important;\n",
    "        }}\n",
    "\n",
    "        /* Active tabs and highlights based on accent color */\n",
    "        .stTabs [aria-selected=\\\"true\\\"] {{\n",
    "            background-color: #000000 !important;\n",
    "            border-bottom: 3px solid {accent_color} !important;\n",
    "            color: {accent_color} !important;\n",
    "        }}\n",
    "\n",
    "        /* Buttons styled with accent color */\n",
    "        .stButton button {{\n",
    "            background-color: {accent_color} !important;\n",
    "            color: white !important;\n",
    "        }}\n",
    "\n",
    "        .stButton button:hover {{\n",
    "            filter: brightness(85%);\n",
    "        }}\n",
    "\n",
    "        /* Warning message */\n",
    "        div.stAlert {{\n",
    "            background-color: #4a0000 !important;\n",
    "            color: white !important;\n",
    "        }}\n",
    "\n",
    "        /* Input fields */\n",
    "        .stTextInput input, .stTextArea textarea, .stSelectbox div {{\n",
    "            background-color: #222222 !important;\n",
    "            color: white !important;\n",
    "        }}\n",
    "\n",
    "        /* Horizontal rule black and accent color gradient */\n",
    "        hr {{\n",
    "            border: none;\n",
    "            height: 2px;\n",
    "            background-image: linear-gradient(to right, black 50%, {accent_color} 50%);\n",
    "        }}\n",
    "\n",
    "        /* General markdown text */\n",
    "        .stMarkdown, .stMarkdown p {{\n",
    "            color: white !important;\n",
    "        }}\n",
    "\n",
    "        /* Skill tags styling */\n",
    "        .skill-tag {{\n",
    "            display: inline-block;\n",
    "            background-color: {accent_color};\n",
    "            color: white;\n",
    "            padding: 5px 12px;\n",
    "            border-radius: 15px;\n",
    "            margin: 5px;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "\n",
    "        .skill-tag.missing {{\n",
    "            background-color: #444;\n",
    "            color: #ccc;\n",
    "        }}\n",
    "\n",
    "        /* Horizontal layout for Strengths and Improvements */\n",
    "        .strengths-improvements {{\n",
    "            display: flex;\n",
    "            gap: 20px;\n",
    "        }}\n",
    "\n",
    "        .strengths-improvements > div {{\n",
    "            flex: 1;\n",
    "        }}\n",
    "        \n",
    "        /* Card styling for sections */\n",
    "        .card {{\n",
    "            background-color: #111111;\n",
    "            border-radius: 10px;\n",
    "            padding: 20px;\n",
    "            margin-bottom: 20px;\n",
    "            border-left: 4px solid {accent_color};\n",
    "        }}\n",
    "        \n",
    "        /* Improvement suggestion styling */\n",
    "        .improvement-item {{\n",
    "            background-color: #222222;\n",
    "            padding: 15px;\n",
    "            margin: 10px 0;\n",
    "            border-radius: 5px;\n",
    "        }}\n",
    "        \n",
    "        /* Before-after comparison */\n",
    "        .comparison-container {{\n",
    "            display: flex;\n",
    "            gap: 20px;\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        \n",
    "        .comparison-box {{\n",
    "            flex: 1;\n",
    "            background-color: #333333;\n",
    "            padding: 15px;\n",
    "            border-radius: 5px;\n",
    "        }}\n",
    "        \n",
    "        /* Weakness detail styling */\n",
    "        .weakness-detail {{\n",
    "            background-color: #330000;\n",
    "            padding: 10px 15px;\n",
    "            margin: 5px 0;\n",
    "            border-radius: 5px;\n",
    "            border-left: 3px solid #ff6666;\n",
    "        }}\n",
    "        \n",
    "        /* Solution styling */\n",
    "        .solution-detail {{\n",
    "            background-color: #003300;\n",
    "            padding: 10px 15px;\n",
    "            margin: 5px 0;\n",
    "            border-radius: 5px;\n",
    "            border-left: 3px solid #66ff66;\n",
    "        }}\n",
    "        \n",
    "        /* Example detail styling */\n",
    "        .example-detail {{\n",
    "            background-color: #000033;\n",
    "            padding: 10px 15px;\n",
    "            margin: 5px 0;\n",
    "            border-radius: 5px;\n",
    "            border-left: 3px solid #6666ff;\n",
    "        }}\n",
    "        \n",
    "        /* Download button styling */\n",
    "        .download-btn {{\n",
    "            display: inline-block;\n",
    "            background-color: {accent_color};\n",
    "            color: white;\n",
    "            padding: 8px 16px;\n",
    "            border-radius: 5px;\n",
    "            text-decoration: none;\n",
    "            margin: 10px 0;\n",
    "            text-align: center;\n",
    "        }}\n",
    "        \n",
    "        .download-btn:hover {{\n",
    "            filter: brightness(85%);\n",
    "        }}\n",
    "        \n",
    "        /* Pie chart styling */\n",
    "        .pie-chart-container {{\n",
    "            padding: 10px;\n",
    "            background-color: #111111;\n",
    "            border-radius: 10px;\n",
    "            margin-bottom: 15px;\n",
    "        }}\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "def setup_sidebar():\n",
    "    with st.sidebar:\n",
    "        st.header(\"Configuration\")\n",
    "        provider_options=[\"Ollama\",\"Gemini\",\"Groq\",\"OpenAI\"]\n",
    "        select_provider = st.selectbox(\"Select the Provider\",provider_options)\n",
    "        if select_provider!=\"Ollama\":\n",
    "            st.subheader(\"API Keys\")\n",
    "            openai_api_key = st.text_input(\"OpenAI API Key\", type=\"password\")\n",
    "        else:\n",
    "            openai_api_key=\"\"\n",
    "        st.markdown(\"---\")\n",
    "        \n",
    "        \n",
    "        st.subheader(\"Theme\")\n",
    "        theme_color = st.color_picker(\"Accent Color\", \"#d32f2f\")\n",
    "        st.markdown(f\"\"\"\n",
    "        <style>\n",
    "        .stButton button, .main-header, .stTabs [aria-selected=\"true\"] {{\n",
    "            background-color: {theme_color} !important;\n",
    "            border-color: {theme_color} !important;\n",
    "        }}\n",
    "        </style>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        \n",
    "        st.markdown(\"---\")\n",
    "        \n",
    "        st.markdown(\"\"\"\n",
    "        <div style=\"text-align: center; margin-top: 20px;\">\n",
    "            <p>üöÄ Recruiter Recruitment Agent</p>\n",
    "            <p style=\"font-size: 0.8rem; color: #666;\">v1.0.0</p>\n",
    "        </div>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        \n",
    "        return {\n",
    "            \"selected_provider\":select_provider,\n",
    "            \"openai_api_key\": openai_api_key,\n",
    "            \"theme_color\": theme_color\n",
    "        }\n",
    "\n",
    "def role_selection_section(role_requirements):\n",
    "    st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
    "    \n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        role = st.selectbox(\"Select the role you're applying for:\", list(role_requirements.keys()))\n",
    "    \n",
    "    with col2:\n",
    "        upload_jd = st.checkbox(\"Upload custom job description instead\")\n",
    "    \n",
    "    custom_jd = None\n",
    "    if upload_jd:\n",
    "        custom_jd_file = st.file_uploader(\"Upload job description (PDF or TXT)\", type=[\"pdf\", \"txt\"])\n",
    "        if custom_jd_file:\n",
    "            st.success(\"Custom job description uploaded!\")\n",
    "            custom_jd = custom_jd_file\n",
    "    \n",
    "    if not upload_jd:\n",
    "        st.info(f\"Required skills: {', '.join(role_requirements[role])}\")\n",
    "        st.markdown(f\"<p>Cutoff Score for selection: <b>{75}/100</b></p>\", unsafe_allow_html=True)\n",
    "    \n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    return role, custom_jd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd79c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_upload_section():\n",
    "    st.markdown(\"\"\"\n",
    "    <div class=\"card\">\n",
    "        <h3>üìÑ Upload Your Resume</h3>\n",
    "        <p>Supported format: PDF</p>\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    uploaded_resume = st.file_uploader(\"\", type=[\"pdf\"], label_visibility=\"collapsed\")\n",
    "    \n",
    "    return uploaded_resume\n",
    "\n",
    "\n",
    "\n",
    "def create_score_pie_chart(score):\n",
    "    \"\"\"Create a professional pie chart for the score visualization\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(4, 4), facecolor='#111111')\n",
    "    \n",
    "    # Data\n",
    "    sizes = [score, 100 - score]\n",
    "    labels = ['', '']  # We'll use annotation instead\n",
    "    colors = [\"#d32f2f\", \"#333333\"]\n",
    "    explode = (0.05, 0)  # explode the 1st slice (Score)\n",
    "    \n",
    "    # Plot\n",
    "    wedges, texts = ax.pie(\n",
    "        sizes, \n",
    "        labels=labels, \n",
    "        colors=colors,\n",
    "        explode=explode, \n",
    "        startangle=90,\n",
    "        wedgeprops={'width': 0.5, 'edgecolor': 'black', 'linewidth': 1}\n",
    "    )\n",
    "    \n",
    "    # Draw a circle in the center to make it a donut chart\n",
    "    centre_circle = plt.Circle((0, 0), 0.25, fc='#111111')\n",
    "    ax.add_artist(centre_circle)\n",
    "    \n",
    "    # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Add score text in the center\n",
    "    ax.text(0, 0, f\"{score}%\", \n",
    "            ha='center', va='center', \n",
    "            fontsize=24, fontweight='bold', \n",
    "            color='white')\n",
    "    \n",
    "    # Add pass/fail indicator\n",
    "    status = \"PASS\" if score >= 75 else \"FAIL\"\n",
    "    status_color = \"#4CAF50\" if score >= 75 else \"#d32f2f\"\n",
    "    ax.text(0, -0.15, status, \n",
    "            ha='center', va='center', \n",
    "            fontsize=14, fontweight='bold', \n",
    "            color=status_color)\n",
    "    \n",
    "    # Set the background color\n",
    "    ax.set_facecolor('#111111')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def display_analysis_results(analysis_result):\n",
    "    if not analysis_result:\n",
    "        return\n",
    "\n",
    "    overall_score = analysis_result.get('overall_score', 0)\n",
    "    selected = analysis_result.get(\"selected\", False)\n",
    "    skill_scores = analysis_result.get(\"skill_scores\", {})\n",
    "    detailed_weaknesses = analysis_result.get(\"detailed_weaknesses\", [])\n",
    "\n",
    "    st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\n",
    "        '<div style=\"text-align: right; font-size: 0.8rem; color: #888; margin-bottom: 10px;\">Powered by Recruiter Recruitment</div>',\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "    col1, col2 = st.columns([1, 2])\n",
    "\n",
    "    with col1:\n",
    "        st.metric(\"Overall Score\", f\"{overall_score}/100\")\n",
    "        fig = create_score_pie_chart(overall_score)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "    with col2:\n",
    "        if selected:\n",
    "            st.markdown(\"<h2 style='color:#4CAF50;'>‚úÖ Congratulations! You have been shortlisted.</h2>\", unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.markdown(\"<h2 style='color:#d32f2f;'>‚ùå Unfortunately, you were not selected.</h2>\", unsafe_allow_html=True)\n",
    "        st.write(analysis_result.get('reasoning', ''))\n",
    "\n",
    "    st.markdown('<hr>', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown('<div class=\"strengths-improvements\">', unsafe_allow_html=True)\n",
    "\n",
    "    # Strengths\n",
    "    st.markdown('<div>', unsafe_allow_html=True)\n",
    "    st.subheader(\"üåü Strengths\")\n",
    "    strengths = analysis_result.get(\"strengths\", [])\n",
    "    if strengths:\n",
    "        for skill in strengths:\n",
    "            st.markdown(f'<div class=\"skill-tag\">{skill} ({skill_scores.get(skill, \"N/A\")}/10)</div>', unsafe_allow_html=True)\n",
    "    else:\n",
    "        st.write(\"No notable strengths identified.\")\n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    # Weaknesses\n",
    "    \n",
    "    st.markdown('<div>', unsafe_allow_html=True)\n",
    "    st.subheader(\"üö© Areas for Improvement\")\n",
    "    missing_skills = analysis_result.get(\"missing_skills\", [])\n",
    "    if missing_skills:\n",
    "        for skill in missing_skills:\n",
    "            st.markdown(f'<div class=\"skill-tag missing\">{skill} ({skill_scores.get(skill, \"N/A\")}/10)</div>', unsafe_allow_html=True)\n",
    "    else:\n",
    "        st.write(\"No significant areas for improvement.\")\n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Detailed weaknesses section\n",
    "    if detailed_weaknesses:\n",
    "        st.markdown('<hr>', unsafe_allow_html=True)\n",
    "        st.subheader(\"üìä Detailed Weakness Analysis\")\n",
    "        \n",
    "        for weakness in detailed_weaknesses:\n",
    "            skill_name = weakness.get('skill', '')\n",
    "            score = weakness.get('score', 0)\n",
    "            \n",
    "            with st.expander(f\"{skill_name} (Score: {score}/10)\"):\n",
    "                # Clean detail display\n",
    "                detail = weakness.get('detail', 'No specific details provided.')\n",
    "                # Clean JSON formatting if it appears in the text\n",
    "                if detail.startswith('```json') or '{' in detail:\n",
    "                    detail = \"The resume lacks examples of this skill.\"\n",
    "                \n",
    "                st.markdown(f'<div class=\"weakness-detail\"><strong>Issue:</strong> {detail}</div>', \n",
    "                           unsafe_allow_html=True)\n",
    "                \n",
    "                # Display improvement suggestions if available\n",
    "                if 'suggestions' in weakness and weakness['suggestions']:\n",
    "                    st.markdown(\"<strong>How to improve:</strong>\", unsafe_allow_html=True)\n",
    "                    for i, suggestion in enumerate(weakness['suggestions']):\n",
    "                        st.markdown(f'<div class=\"solution-detail\">{i+1}. {suggestion}</div>', \n",
    "                                   unsafe_allow_html=True)\n",
    "                \n",
    "                # Display example if available\n",
    "                if 'example' in weakness and weakness['example']:\n",
    "                    st.markdown(\"<strong>Example addition:</strong>\", unsafe_allow_html=True)\n",
    "                    st.markdown(f'<div class=\"example-detail\">{weakness[\"example\"]}</div>', \n",
    "                               unsafe_allow_html=True)\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    col1, col2, col3 = st.columns([1, 2, 1])\n",
    "    with col2:\n",
    "        report_content = f\"\"\"\n",
    "# Recruiter Recruitment - Resume Analysis Report\n",
    "\n",
    "## Overall Score: {overall_score}/100\n",
    "\n",
    "Status: {\"‚úÖ Shortlisted\" if selected else \"‚ùå Not Selected\"}\n",
    "\n",
    "## Analysis Reasoning\n",
    "{analysis_result.get('reasoning', 'No reasoning provided.')}\n",
    "\n",
    "## Strengths\n",
    "{\", \".join(strengths if strengths else [\"None identified\"])}\n",
    "\n",
    "## Areas for Improvement\n",
    "{\", \".join(missing_skills if missing_skills else [\"None identified\"])}\n",
    "\n",
    "## Detailed Weakness Analysis\n",
    "\"\"\"\n",
    "        # Add detailed weaknesses to report\n",
    "        for weakness in detailed_weaknesses:\n",
    "            skill_name = weakness.get('skill', '')\n",
    "            score = weakness.get('score', 0)\n",
    "            detail = weakness.get('detail', 'No specific details provided.')\n",
    "            \n",
    "            # Clean JSON formatting if it appears in the text\n",
    "            if detail.startswith('```json') or '{' in detail:\n",
    "                detail = \"The resume lacks examples of this skill.\"\n",
    "                \n",
    "            report_content += f\"\\n### {skill_name} (Score: {score}/10)\\n\"\n",
    "            report_content += f\"Issue: {detail}\\n\"\n",
    "            \n",
    "            # Add suggestions to report\n",
    "            if 'suggestions' in weakness and weakness['suggestions']:\n",
    "                report_content += \"\\nImprovement suggestions:\\n\"\n",
    "                for i, sugg in enumerate(weakness['suggestions']):\n",
    "                    report_content += f\"- {sugg}\\n\"\n",
    "            \n",
    "            # Add example to report\n",
    "            if 'example' in weakness and weakness['example']:\n",
    "                report_content += f\"\\nExample: {weakness['example']}\\n\"\n",
    "            \n",
    "        report_content += \"\\n---\\nAnalysis provided by Recruiter Recruitment Agent\"\n",
    "        \n",
    "        report_b64 = base64.b64encode(report_content.encode()).decode()\n",
    "        href = f'<a class=\"download-btn\" href=\"data:text/plain;base64,{report_b64}\" download=\"Recruiter_resume_analysis.txt\">üìä Download Analysis Report</a>'\n",
    "        st.markdown(href, unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resume_qa_section(has_resume, ask_question_func=None):\n",
    "    if not has_resume:\n",
    "        st.warning(\"Please upload and analyze a resume first.\")\n",
    "        return\n",
    "    \n",
    "    st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
    "    \n",
    "    st.subheader(\"Ask Questions About the Resume\")\n",
    "    user_question = st.text_input(\"Enter your question about the resume:\", placeholder=\"What is the candidate's most recent experience?\")\n",
    "    \n",
    "    if user_question and ask_question_func:\n",
    "        with st.spinner(\"Searching resume and generating response...\"):\n",
    "            response = ask_question_func(user_question)\n",
    "            \n",
    "            st.markdown('<div style=\"background-color: #111122; padding: 15px; border-radius: 5px; border-left: 5px solid #d32f2f;\">', unsafe_allow_html=True)\n",
    "            st.write(response)\n",
    "            st.markdown('</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Add example questions\n",
    "    with st.expander(\"Example Questions\"):\n",
    "        example_questions = [\n",
    "            \"What is the candidate's most recent role?\",\n",
    "            \"How many years of experience does the candidate have with Python?\",\n",
    "            \"What educational qualifications does the candidate have?\",\n",
    "            \"What are the candidate's key achievements?\",\n",
    "            \"Has the candidate managed teams before?\",\n",
    "            \"What projects has the candidate worked on?\",\n",
    "            \"Does the candidate have experience with cloud technologies?\"\n",
    "        ]\n",
    "        \n",
    "        for question in example_questions:\n",
    "            if st.button(question, key=f\"q_{question}\"):\n",
    "                st.session_state.current_question = question\n",
    "                st.experimental_rerun()\n",
    "    \n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "def interview_questions_section(has_resume, generate_questions_func=None):\n",
    "    if not has_resume:\n",
    "        st.warning(\"Please upload and analyze a resume first.\")\n",
    "        return\n",
    "    \n",
    "    st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        question_types = st.multiselect(\n",
    "            \"Select question types:\",\n",
    "            [\"Basic\", \"Technical\", \"Experience\", \"Scenario\", \"Coding\", \"Behavioral\"],\n",
    "            default=[\"Basic\", \"Technical\"]\n",
    "        )\n",
    "    \n",
    "    with col2:\n",
    "        difficulty = st.select_slider(\n",
    "            \"Question difficulty:\",\n",
    "            options=[\"Easy\", \"Medium\", \"Hard\"],\n",
    "            value=\"Medium\"\n",
    "        )\n",
    "    \n",
    "    num_questions = st.slider(\"Number of questions:\", 3, 15, 5)\n",
    "    \n",
    "    if st.button(\"Generate Interview Questions\"):\n",
    "        if generate_questions_func:\n",
    "            with st.spinner(\"Generating personalized interview questions...\"):\n",
    "                questions = generate_questions_func(question_types, difficulty, num_questions)\n",
    "                \n",
    "                # Create content for download\n",
    "                download_content = f\"# Recruiter Recruitment - Interview Questions\\n\\n\"\n",
    "                download_content += f\"Difficulty: {difficulty}\\n\"\n",
    "                download_content += f\"Types: {', '.join(question_types)}\\n\\n\"\n",
    "                \n",
    "                for i, (q_type, question) in enumerate(questions):\n",
    "                    with st.expander(f\"{q_type}: {question[:50]}...\"):\n",
    "                        st.write(question)\n",
    "                        \n",
    "                        # For coding questions, add code editor\n",
    "                        if q_type == \"Coding\":\n",
    "                            st.code(\"# Write your solution here\", language=\"python\")\n",
    "                    \n",
    "                    # Add to download content\n",
    "                    download_content += f\"## {i+1}. {q_type} Question\\n\\n\"\n",
    "                    download_content += f\"{question}\\n\\n\"\n",
    "                    if q_type == \"Coding\":\n",
    "                        download_content += \"```python\\n# Write your solution here\\n```\\n\\n\"\n",
    "                \n",
    "                # Add Recruiter branding to download content\n",
    "                download_content += \"\\n---\\nQuestions generated by Recruiter Recruitment Agent\"\n",
    "                \n",
    "                # Add download button\n",
    "                if questions:\n",
    "                    st.markdown(\"---\")\n",
    "                    questions_bytes = download_content.encode()\n",
    "                    b64 = base64.b64encode(questions_bytes).decode()\n",
    "                    href = f'<a class=\"download-btn\" href=\"data:text/markdown;base64,{b64}\" download=\"Recruiter_interview_questions.md\">üìù Download All Questions</a>'\n",
    "                    st.markdown(href, unsafe_allow_html=True)\n",
    "    \n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "def resume_improvement_section(has_resume, improve_resume_func=None):\n",
    "    if not has_resume:\n",
    "        st.warning(\"Please upload and analyze a resume first.\")\n",
    "        return\n",
    "    \n",
    "    st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
    "    \n",
    "    improvement_areas = st.multiselect(\n",
    "        \"Select areas to improve:\",\n",
    "        [\"Content\", \"Format\", \"Skills Highlighting\", \"Experience Description\", \"Education\", \"Projects\", \"Achievements\", \"Overall Structure\"],\n",
    "        default=[\"Content\", \"Skills Highlighting\"]\n",
    "    )\n",
    "    \n",
    "    target_role = st.text_input(\"Target role (optional):\", placeholder=\"e.g., Senior Data Scientist at Google\")\n",
    "    \n",
    "    if st.button(\"Generate Resume Improvements\"):\n",
    "        if improve_resume_func:\n",
    "            with st.spinner(\"Analyzing and generating improvements...\"):\n",
    "                improvements = improve_resume_func(improvement_areas, target_role)\n",
    "                \n",
    "                # Create content for download\n",
    "                download_content = f\"# Recruiter Recruitment - Resume Improvement Suggestions\\n\\nTarget Role: {target_role if target_role else 'Not specified'}\\n\\n\"\n",
    "                \n",
    "                for area, suggestions in improvements.items():\n",
    "                    with st.expander(f\"Improvements for {area}\", expanded=True):\n",
    "                        st.markdown(f\"<p>{suggestions['description']}</p>\", unsafe_allow_html=True)\n",
    "                        \n",
    "                        st.subheader(\"Specific Suggestions\")\n",
    "                        for i, suggestion in enumerate(suggestions[\"specific\"]):\n",
    "                            st.markdown(f'<div class=\"solution-detail\"><strong>{i+1}.</strong> {suggestion}</div>', unsafe_allow_html=True)\n",
    "                        \n",
    "                        if \"before_after\" in suggestions:\n",
    "                            st.markdown('<div class=\"comparison-container\">', unsafe_allow_html=True)\n",
    "                            \n",
    "                            st.markdown('<div class=\"comparison-box\">', unsafe_allow_html=True)\n",
    "                            st.markdown(\"<strong>Before:</strong>\", unsafe_allow_html=True)\n",
    "                            st.markdown(f\"<pre>{suggestions['before_after']['before']}</pre>\", unsafe_allow_html=True)\n",
    "                            st.markdown('</div>', unsafe_allow_html=True)\n",
    "                            \n",
    "                            st.markdown('<div class=\"comparison-box\">', unsafe_allow_html=True)\n",
    "                            st.markdown(\"<strong>After:</strong>\", unsafe_allow_html=True) \n",
    "                            st.markdown(f\"<pre>{suggestions['before_after']['after']}</pre>\", unsafe_allow_html=True)\n",
    "                            st.markdown('</div>', unsafe_allow_html=True)\n",
    "                            \n",
    "                            st.markdown('</div>', unsafe_allow_html=True)\n",
    "                    \n",
    "                    # Add to download content\n",
    "                    download_content += f\"## Improvements for {area}\\n\\n\"\n",
    "                    download_content += f\"{suggestions['description']}\\n\\n\"\n",
    "                    download_content += \"### Specific Suggestions\\n\\n\"\n",
    "                    for i, suggestion in enumerate(suggestions[\"specific\"]):\n",
    "                        download_content += f\"{i+1}. {suggestion}\\n\"\n",
    "                    download_content += \"\\n\"\n",
    "                    \n",
    "                    if \"before_after\" in suggestions:\n",
    "                        download_content += \"### Before\\n\\n\"\n",
    "                        download_content += f\"```\\n{suggestions['before_after']['before']}\\n```\\n\\n\"\n",
    "                        download_content += \"### After\\n\\n\"\n",
    "                        download_content += f\"```\\n{suggestions['before_after']['after']}\\n```\\n\\n\"\n",
    "                \n",
    "                # Add Recruiter branding to download content\n",
    "                download_content += \"\\n---\\nProvided by Recruiter Recruitment Agent\"\n",
    "                \n",
    "                # Add download button\n",
    "                st.markdown(\"---\")\n",
    "                report_bytes = download_content.encode()\n",
    "                b64 = base64.b64encode(report_bytes).decode()\n",
    "                href = f'<a class=\"download-btn\" href=\"data:text/markdown;base64,{b64}\" download=\"Recruiter_resume_improvements.md\">üìù Download All Suggestions</a>'\n",
    "                st.markdown(href, unsafe_allow_html=True)\n",
    "    \n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "def improved_resume_section(has_resume, get_improved_resume_func=None):\n",
    "    if not has_resume:\n",
    "        st.warning(\"Please upload and analyze a resume first.\")\n",
    "        return\n",
    "    \n",
    "    st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
    "    \n",
    "    target_role = st.text_input(\"Target role:\", placeholder=\"e.g., Senior Software Engineer\")\n",
    "    highlight_skills = st.text_area(\"Paste your JD to get updated Resume\", placeholder=\"e.g., Python, React, Cloud Architecture\")\n",
    "    \n",
    "    if st.button(\"Generate Improved Resume\"):\n",
    "        if get_improved_resume_func:\n",
    "            with st.spinner(\"Creating improved resume...\"):\n",
    "                improved_resume = get_improved_resume_func(target_role, highlight_skills)\n",
    "                \n",
    "                st.subheader(\"Improved Resume\")\n",
    "                st.text_area(\"\", improved_resume, height=400)\n",
    "                \n",
    "                # Download buttons\n",
    "                col1, col2 = st.columns(2)\n",
    "                \n",
    "                with col1:\n",
    "                    # Text file download\n",
    "                    resume_bytes = improved_resume.encode()\n",
    "                    b64 = base64.b64encode(resume_bytes).decode()\n",
    "                    href = f'<a class=\"download-btn\" href=\"data:file/txt;base64,{b64}\" download=\"Recruiter_improved_resume.txt\">üìÑ Download as TXT</a>'\n",
    "                    st.markdown(href, unsafe_allow_html=True)\n",
    "                \n",
    "                with col2:\n",
    "                    # Markdown file download\n",
    "                    md_content = f\"\"\"# {target_role if target_role else 'Professional'} Resume\n",
    "\n",
    "{improved_resume}\n",
    "\n",
    "---\n",
    "Resume enhanced by Recruiter Recruitment Agent\n",
    "\"\"\"\n",
    "                    md_bytes = md_content.encode()\n",
    "                    md_b64 = base64.b64encode(md_bytes).decode()\n",
    "                    md_href = f'<a class=\"download-btn\" href=\"data:text/markdown;base64,{md_b64}\" download=\"Recruiter_improved_resume.md\">üìù Download as Markdown</a>'\n",
    "                    st.markdown(md_href, unsafe_allow_html=True)\n",
    "    \n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "def create_tabs():\n",
    "    return st.tabs([\n",
    "        \"Resume Analysis\", \n",
    "        \"Resume Q&A\", \n",
    "        \"Interview Questions\", \n",
    "        \"Resume Improvement\", \n",
    "        \"Improved Resume\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284aa5d",
   "metadata": {},
   "source": [
    "# APP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157cb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d06303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import atexit\n",
    "import ui\n",
    "import agents\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"ReCrUtEr Recruitment Agent\",\n",
    "    page_icon=\"üöÄ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "ROLE_REQUIREMENTS = {\n",
    "    \"AI/ML Engineer\": [\n",
    "        \"Python\", \"PyTorch\", \"TensorFlow\", \"Machine Learning\", \"Deep Learning\",\n",
    "        \"MLOps\", \"Scikit-Learn\", \"NLP\", \"Computer Vision\", \"Reinforcement Learning\",\n",
    "        \"Hugging Face\", \"Data Engineering\", \"Feature Engineering\", \"AutoML\"\n",
    "    ],\n",
    "    \"Frontend Engineer\": [\n",
    "        \"React\", \"Vue\", \"Angular\", \"HTML5\", \"CSS3\", \"JavaScript\", \"TypeScript\",\n",
    "        \"Next.js\", \"Svelte\", \"Bootstrap\", \"Tailwind CSS\", \"GraphQL\", \"Redux\",\n",
    "        \"WebAssembly\", \"Three.js\", \"Performance Optimization\"\n",
    "    ],\n",
    "    \"Backend Engineer\": [\n",
    "        \"Python\", \"Java\", \"Node.js\", \"REST APIs\", \"Cloud services\", \"Kubernetes\",\n",
    "        \"Docker\", \"GraphQL\", \"Microservices\", \"gRPC\", \"Spring Boot\", \"Flask\",\n",
    "        \"FastAPI\", \"SQL & NoSQL Databases\", \"Redis\", \"RabbitMQ\", \"CI/CD\"\n",
    "    ],\n",
    "    \"Data Engineer\": [\n",
    "        \"Python\", \"SQL\", \"Apache Spark\", \"Hadoop\", \"Kafka\", \"ETL Pipelines\",\n",
    "        \"Airflow\", \"BigQuery\", \"Redshift\", \"Data Warehousing\", \"Snowflake\",\n",
    "        \"Azure Data Factory\", \"GCP\", \"AWS Glue\", \"DBT\"\n",
    "    ],\n",
    "    \"DevOps Engineer\": [\n",
    "        \"Kubernetes\", \"Docker\", \"Terraform\", \"CI/CD\", \"AWS\", \"Azure\", \"GCP\",\n",
    "        \"Jenkins\", \"Ansible\", \"Prometheus\", \"Grafana\", \"Helm\", \"Linux Administration\",\n",
    "        \"Networking\", \"Site Reliability Engineering (SRE)\"\n",
    "    ],\n",
    "    \"Full Stack Developer\": [\n",
    "        \"JavaScript\", \"TypeScript\", \"React\", \"Node.js\", \"Express\", \"MongoDB\",\n",
    "        \"SQL\", \"HTML5\", \"CSS3\", \"RESTful APIs\", \"Git\", \"CI/CD\", \"Cloud Services\",\n",
    "        \"Responsive Design\", \"Authentication & Authorization\"\n",
    "    ],\n",
    "    \"Product Manager\": [\n",
    "        \"Product Strategy\", \"User Research\", \"Agile Methodologies\", \"Roadmapping\",\n",
    "        \"Market Analysis\", \"Stakeholder Management\", \"Data Analysis\", \"User Stories\",\n",
    "        \"Product Lifecycle\", \"A/B Testing\", \"KPI Definition\", \"Prioritization\",\n",
    "        \"Competitive Analysis\", \"Customer Journey Mapping\"\n",
    "    ],\n",
    "    \"Data Scientist\": [\n",
    "        \"Python\", \"R\", \"SQL\", \"Machine Learning\", \"Statistics\", \"Data Visualization\",\n",
    "        \"Pandas\", \"NumPy\", \"Scikit-learn\", \"Jupyter\", \"Hypothesis Testing\",\n",
    "        \"Experimental Design\", \"Feature Engineering\", \"Model Evaluation\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize session state variables\n",
    "if 'resume_agent' not in st.session_state:\n",
    "    st.session_state.resume_agent = None\n",
    "\n",
    "if 'resume_analyzed' not in st.session_state:\n",
    "    st.session_state.resume_analyzed = False\n",
    "\n",
    "if 'analysis_result' not in st.session_state:\n",
    "    st.session_state.analysis_result = None\n",
    "\n",
    "def setup_agent(config):\n",
    "    \"\"\"Set up the resume analysis agent with the provided configuration\"\"\"\n",
    "    if not config[\"openai_api_key\"]:\n",
    "        st.error(\"‚ö†Ô∏è Please enter your OpenAI API Key in the sidebar.\")\n",
    "        return None\n",
    "\n",
    "    # Initialize or update the agent with the API key\n",
    "    if st.session_state.resume_agent is None:\n",
    "        st.session_state.resume_agent = ResumeAnalysisAgent(api_key=config[\"openai_api_key\"],llm_name=config[\"selected_provider\"])\n",
    "    else:\n",
    "        st.session_state.resume_agent.api_key = config[\"openai_api_key\"]\n",
    "\n",
    "    return st.session_state.resume_agent\n",
    "def analyze_resume(agent, resume_file, role, custom_jd):\n",
    "    \"\"\"Analyze the resume with the agent\"\"\"\n",
    "    if not resume_file:\n",
    "        st.error(\"‚ö†Ô∏è Please upload a resume.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with st.spinner(\"üîç Analyzing resume... This may take a minute.\"):\n",
    "            if custom_jd:\n",
    "                result = agent.analyze_resume(resume_file, custom_jd=custom_jd)\n",
    "            else:\n",
    "                result = agent.analyze_resume(resume_file, role_requirements=ROLE_REQUIREMENTS[role])\n",
    "\n",
    "            st.session_state.resume_analyzed = True\n",
    "            st.session_state.analysis_result = result\n",
    "            return result\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ö†Ô∏è Error analyzing resume: {e}\")\n",
    "        return None\n",
    "\n",
    "def ask_question(agent, question):\n",
    "    \"\"\"Ask a question about the resume\"\"\"\n",
    "    try:\n",
    "        with st.spinner(\"Generating response...\"):\n",
    "            response = agent.ask_question(question)\n",
    "            return response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "\n",
    "def generate_interview_questions(agent, question_types, difficulty, num_questions):\n",
    "    \"\"\"Generate interview questions based on the resume\"\"\"\n",
    "    try:\n",
    "        with st.spinner(\"Generating personalized interview questions...\"):\n",
    "            questions = agent.generate_interview_questions(question_types, difficulty, num_questions)\n",
    "            return questions\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ö†Ô∏è Error generating questions: {e}\")\n",
    "        return []\n",
    "\n",
    "def improve_resume(agent, improvement_areas, target_role):\n",
    "    \"\"\"Generate resume improvement suggestions\"\"\"\n",
    "    try:\n",
    "        with st.spinner(\"Analyzing and generating improvements...\"):\n",
    "            return agent.improve_resume(improvement_areas, target_role)\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ö†Ô∏è Error generating improvements: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "\n",
    "def get_improved_resume(agent, target_role, highlight_skills):\n",
    "    \"\"\"Get an improved version of the resume\"\"\"\n",
    "    try:\n",
    "        with st.spinner(\"Creating improved resume...\"):\n",
    "            return agent.get_improved_resume(target_role, highlight_skills)\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ö†Ô∏è Error creating improved resume: {e}\")\n",
    "        return \"Error generating improved resume.\"\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Clean up resources when the app exits\"\"\"\n",
    "    if st.session_state.resume_agent:\n",
    "        st.session_state.resume_agent.cleanup()\n",
    "\n",
    "\n",
    "\n",
    "# Register cleanup function\n",
    "atexit.register(cleanup)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Setup page UI\n",
    "    ui.setup_page()\n",
    "    ui.display_header()\n",
    "\n",
    "    # Set up sidebar and get configuration\n",
    "    config = ui.setup_sidebar()\n",
    "\n",
    "    # Set up the agent\n",
    "    agent = setup_agent(config)\n",
    "\n",
    "    # Create tabs for different functionalities\n",
    "    tabs = ui.create_tabs()\n",
    "\n",
    "    # Tab 1: Resume Analysis\n",
    "    with tabs[0]:\n",
    "        role, custom_jd = ui.role_selection_section(ROLE_REQUIREMENTS)\n",
    "        uploaded_resume = ui.resume_upload_section()\n",
    "\n",
    "        col1, col2, col3 = st.columns([1, 1, 1])\n",
    "        with col2:\n",
    "            if st.button(\"üîç Analyze Resume\", type=\"primary\"):\n",
    "                if agent and uploaded_resume:\n",
    "                    # Just store the result, don't display it here\n",
    "                    analyze_resume(agent, uploaded_resume, role, custom_jd)\n",
    "                    \n",
    "        # Display analysis result (only once)\n",
    "        if st.session_state.analysis_result:\n",
    "            ui.display_analysis_results(st.session_state.analysis_result)\n",
    "\n",
    "    # Tab 2: Resume Q&A\n",
    "    with tabs[1]:\n",
    "        # We need to ensure the agent and resume are available\n",
    "        if st.session_state.resume_analyzed and st.session_state.resume_agent:\n",
    "            ui.resume_qa_section(\n",
    "                has_resume=True,  # Explicitly set to True since we checked above\n",
    "                ask_question_func=lambda q: ask_question(st.session_state.resume_agent, q)\n",
    "            )\n",
    "        else:\n",
    "            st.warning(\"Please upload and analyze a resume first in the 'Resume Analysis' tab.\")\n",
    "\n",
    "    # Tab 3: Interview Questions\n",
    "    with tabs[2]:\n",
    "        # We need to ensure the agent and resume are available\n",
    "        if st.session_state.resume_analyzed and st.session_state.resume_agent:\n",
    "            ui.interview_questions_section(\n",
    "                has_resume=True,  # Explicitly set to True since we checked above\n",
    "                generate_questions_func=lambda types, diff, num: generate_interview_questions(st.session_state.resume_agent, types, diff, num)\n",
    "            )\n",
    "        else:\n",
    "            st.warning(\"Please upload and analyze a resume first in the 'Resume Analysis' tab.\")\n",
    "\n",
    "    # Tab 4: Resume Improvement\n",
    "    with tabs[3]:\n",
    "        if st.session_state.resume_analyzed and st.session_state.resume_agent:\n",
    "            ui.resume_improvement_section(\n",
    "                has_resume=True,\n",
    "                improve_resume_func=lambda areas, role: improve_resume(st.session_state.resume_agent, areas, role)\n",
    "            )\n",
    "        else:\n",
    "            st.warning(\"Please upload and analyze a resume first in the 'Resume Analysis' tab.\")\n",
    "\n",
    "    # Tab 5: Improved Resume\n",
    "    with tabs[4]:\n",
    "        if st.session_state.resume_analyzed and st.session_state.resume_agent:\n",
    "            ui.improved_resume_section(\n",
    "                has_resume=True,\n",
    "                get_improved_resume_func=lambda role, skills: get_improved_resume(st.session_state.resume_agent, role, skills)\n",
    "            )\n",
    "        else:\n",
    "            st.warning(\"Please upload and analyze a resume first in the 'Resume Analysis' tab.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a3405",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1dece3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "import io\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_ollama import OllamaLLM,OllamaEmbeddings,ChatOllama\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings,GoogleGenerativeAI,ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tempfile\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74c4e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeAnalysisAgent:\n",
    "    def __init__(self,llm_name,api_key=None,cutoff_score=75):\n",
    "        self.api_key = api_key\n",
    "        self.cutoff_score = cutoff_score\n",
    "        self.resume_text = None\n",
    "        self.rag_vectorstore = None\n",
    "        self.analysis_result = None\n",
    "        self.jd_text = None\n",
    "        self.extracted_skills = None\n",
    "        self.llm_name=llm_name\n",
    "        self.resume_weaknesses = []\n",
    "        self.resume_strengths = []\n",
    "        self.improvement_suggestions = {}   \n",
    "    def extract_text_from_pdf(self,pdf_file):\n",
    "        try:\n",
    "            if hasattr(pdf_file,'getvalue'):\n",
    "                pdf_data=pdf_file.getvalue()\n",
    "                pdf_file_like=io.BytesIO(pdf_data)\n",
    "                reader=PyPDF2.PdfReader(pdf_file_like)\n",
    "\n",
    "            else:\n",
    "                pdf_file_like = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "            text=\"\"\n",
    "            for page in reader.pages:\n",
    "                text+=page.extract_text()\n",
    "                return text\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_text_from_txt(self,txt_file):\n",
    "        try:\n",
    "            if hasattr(txt_file,'getvalue'):\n",
    "                return txt_file.getvalue().decode('utf-8')\n",
    "            else:\n",
    "                with open(txt_file,'r',encoding='utf-8') as f:\n",
    "                    return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from text file: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_text_from_file(self, file):\n",
    "        \"\"\"Extract text from a file (PDF or TXT)\"\"\"\n",
    "        if hasattr(file, 'name'):\n",
    "            file_extension = file.name.split('.')[-1].lower()\n",
    "        else:\n",
    "            file_extension = file.split('.')[-1].lower()\n",
    "            \n",
    "        if file_extension == 'pdf':\n",
    "            return self.extract_text_from_pdf(file)\n",
    "        elif file_extension == 'txt':\n",
    "            return self.extract_text_from_txt(file)\n",
    "        else:\n",
    "            print(f\"Unsupported file extension: {file_extension}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def create_rag_vector_store(self, text):\n",
    "        \"\"\"Create a vector store for RAG\"\"\"\n",
    "   \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        \n",
    "        if self.llm_name==\"OpenAI\":\n",
    "            embeddings = OpenAIEmbeddings(api_key=self.api_key)\n",
    "        elif self.llm_name==\"Ollama\":\n",
    "            embeddings=OllamaEmbeddings(model=\"llama3.2\")\n",
    "        elif self.llm_name==\"Gemini\":\n",
    "            embeddings=GoogleGenerativeAIEmbeddings(google_api_key=self.api_key,model=\"models/gemini-embedding-exp-03-07\")\n",
    "        elif self.llm_name == \"Groq\":\n",
    "\n",
    "            embeddings=HuggingFaceEmbeddings(\"sentence-transformers/all-MiniLM-l6-v2\")\n",
    "        vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "        return vectorstore\n",
    "    def create_vector_store(self, text):\n",
    "        \"\"\"Create a simpler vector store for skill analysis\"\"\"\n",
    "        if self.llm_name==\"OpenAI\":\n",
    "            embeddings = OpenAIEmbeddings(api_key=self.api_key)\n",
    "        elif self.llm_name==\"Ollama\":\n",
    "            embeddings=OllamaEmbeddings(model=\"llama3.2\")\n",
    "        elif self.llm_name==\"Gemini\":\n",
    "            embeddings=GoogleGenerativeAIEmbeddings(google_api_key=self.api_key,model=\"models/gemini-embedding-exp-03-07\")\n",
    "        elif self.llm_name == \"Groq\":\n",
    "\n",
    "            embeddings=HuggingFaceEmbeddings(\"sentence-transformers/all-MiniLM-l6-v2\")\n",
    "        vectorstore = FAISS.from_texts([text], embeddings)\n",
    "        return vectorstore\n",
    "    \n",
    "\n",
    "    def analyze_skill(self, qa_chain, skill):\n",
    "        # ! \"\"\"Analyze a skill in the resume\"\"\"\n",
    "        query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by reasoning.\"\n",
    "        response = qa_chain.run(query)\n",
    "        match = re.search(r\"(\\d{1,2})\", response)\n",
    "        score = int(match.group(1)) if match else 0\n",
    "        \n",
    "\n",
    "        reasoning = response.split('.', 1)[1].strip() if '.' in response and len(response.split('.')) > 1 else \"\"\n",
    "        \n",
    "    \n",
    "        return skill, min(score, 10), reasoning\n",
    "    \n",
    "    def analyze_resume_weaknesses(self,model=None):\n",
    "        \"\"\"Analyze specific weaknesses in the resume based on missing skills\"\"\"\n",
    "        if not self.resume_text or not self.extracted_skills or not self.analysis_result:\n",
    "            return []\n",
    "        \n",
    "        weaknesses = []\n",
    "        \n",
    "        for skill in self.analysis_result.get(\"missing_skills\", []):\n",
    "\n",
    "            # llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "            if self.llm_name==\"OpenAI\":\n",
    "                if model==None:\n",
    "                    llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "                else :\n",
    "                    llm = ChatOpenAI(model=model, api_key=self.api_key)\n",
    "\n",
    "            elif self.llm_name==\"Ollama\":\n",
    "                if model==None:\n",
    "                    llm=ChatOllama(model=\"llama3.2\")\n",
    "                else:\n",
    "                    llm=ChatOllama(model=model)\n",
    "\n",
    "            elif self.llm_name==\"Gemini\":\n",
    "                if model==None:\n",
    "                    llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "                else:\n",
    "                    llm=ChatGoogleGenerativeAI(model=model)\n",
    "            elif self.llm_name==\"Groq\":\n",
    "                if model==None:\n",
    "                    llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "                else:\n",
    "                    llm = ChatGroq(model=model)\n",
    "                \n",
    "            \n",
    "             \n",
    "                \n",
    "            prompt = f\"\"\"\n",
    "            Analyze why the resume is weak in demonstrating proficiency in \"{skill}\".\n",
    "            \n",
    "            For your analysis, consider:\n",
    "            1. What's missing from the resume regarding this skill?\n",
    "            2. How could it be improved with specific examples?\n",
    "            3. What specific action items would make this skill stand out?\n",
    "            \n",
    "            Resume Content:\n",
    "            {self.resume_text[:3000]}...\n",
    "            \n",
    "            Provide your response in this JSON format:\n",
    "            {{\n",
    "                \"weakness\": \"A concise description of what's missing or problematic (1-2 sentences)\",\n",
    "                \"improvement_suggestions\": [\n",
    "                    \"Specific suggestion 1\",\n",
    "                    \"Specific suggestion 2\",\n",
    "                    \"Specific suggestion 3\"\n",
    "                ],\n",
    "                \"example_addition\": \"A specific bullet point that could be added to showcase this skill\"\n",
    "            }}\n",
    "            \n",
    "            Return only valid JSON, no other text.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = llm.invoke(prompt)\n",
    "            weakness_content = response.content.strip()\n",
    "            \n",
    "    \n",
    "            try:\n",
    "                weakness_data = json.loads(weakness_content)\n",
    "                \n",
    "                weakness_detail = {\n",
    "                    \"skill\": skill,\n",
    "                    \"score\": self.analysis_result.get(\"skill_scores\", {}).get(skill, 0),\n",
    "                    \"detail\": weakness_data.get(\"weakness\", \"No specific details provided.\"),\n",
    "                    \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "                    \"example\": weakness_data.get(\"example_addition\", \"\")\n",
    "                }\n",
    "                \n",
    "                weaknesses.append(weakness_detail)\n",
    "\n",
    "                self.improvement_suggestions[skill] = {\n",
    "                    \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "                    \"example\": weakness_data.get(\"example_addition\", \"\")\n",
    "                }\n",
    "            except json.JSONDecodeError:\n",
    "             \n",
    "                weaknesses.append({\n",
    "                    \"skill\": skill,\n",
    "                    \"score\": self.analysis_result.get(\"skill_scores\", {}).get(skill, 0),\n",
    "                    \"detail\": weakness_content[:200]  # Truncate if it's not proper JSON\n",
    "                })\n",
    "            \n",
    "        self.resume_weaknesses = weaknesses\n",
    "        return weaknesses\n",
    "    def extract_skills_from_jd(self, jd_text,model=None):\n",
    "        \"\"\"Extract skills from a job description\"\"\"\n",
    "        try:\n",
    "            if self.llm_name==\"OpenAI\":\n",
    "                if model==None:\n",
    "                    llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "                else :\n",
    "                    llm = ChatOpenAI(model=model, api_key=self.api_key)\n",
    "\n",
    "            elif self.llm_name==\"Ollama\":\n",
    "                if model==None:\n",
    "                    llm=ChatOllama(model=\"llama3.2\")\n",
    "                else:\n",
    "                    llm=ChatOllama(model=model)\n",
    "\n",
    "            elif self.llm_name==\"Gemini\":\n",
    "                if model==None:\n",
    "                    llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "                else:\n",
    "                    llm=ChatGoogleGenerativeAI(model=model)\n",
    "            elif self.llm_name==\"Groq\":\n",
    "                if model==None:\n",
    "                    llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "                else:\n",
    "                    llm = ChatGroq(model=model)\n",
    "                \n",
    "            prompt = f\"\"\"\n",
    "            Extract a comprehensive list of technical skills, technologies, and competencies required from this job description. \n",
    "            Format the output as a Python list of strings. Only include the list, nothing else.\n",
    "            \n",
    "            Job Description:\n",
    "            {jd_text}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = llm.invoke(prompt)\n",
    "            skills_text = response.content\n",
    "            \n",
    "      \n",
    "            match = re.search(r'\\[(.*?)\\]', skills_text, re.DOTALL)\n",
    "            if match:\n",
    "                skills_text = match.group(0)\n",
    "            \n",
    "\n",
    "            try:\n",
    "                skills_list = eval(skills_text)\n",
    "                if isinstance(skills_list, list):\n",
    "                    return skills_list\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "         \n",
    "            skills = []\n",
    "            for line in skills_text.split('\\n'):\n",
    "                line = line.strip()\n",
    "                if line.startswith('- ') or line.startswith('* '):\n",
    "                    skill = line[2:].strip()\n",
    "                    if skill:\n",
    "                        skills.append(skill)\n",
    "                elif line.startswith('\"') and line.endswith('\"'):\n",
    "                    skill = line.strip('\"')\n",
    "                    if skill:\n",
    "                        skills.append(skill)\n",
    "            \n",
    "            return skills\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting skills from job description: {e}\")\n",
    "            return []\n",
    "    def semantic_skill_analysis(self, resume_text, skills,model=None):\n",
    "        \"\"\"Analyze skills semantically\"\"\"\n",
    "        vectorstore = self.create_vector_store(resume_text)\n",
    "        retriever = vectorstore.as_retriever()\n",
    "        \n",
    "        if self.llm_name==\"OpenAI\":\n",
    "            if model==None:\n",
    "                llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "            else :\n",
    "                llm = ChatOpenAI(model=model, api_key=self.api_key)\n",
    "\n",
    "        elif self.llm_name==\"Ollama\":\n",
    "            if model==None:\n",
    "                llm=ChatOllama(model=\"llama3.2\")\n",
    "            else:\n",
    "                llm=ChatOllama(model=model)\n",
    "\n",
    "        elif self.llm_name==\"Gemini\":\n",
    "            if model==None:\n",
    "                llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "            else:\n",
    "                llm=ChatGoogleGenerativeAI(model=model)\n",
    "        elif self.llm_name==\"Groq\":\n",
    "            if model==None:\n",
    "                llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "            else:\n",
    "                llm = ChatGroq(model=model)\n",
    "            \n",
    "\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False\n",
    "        )\n",
    "\n",
    "        skill_scores = {}\n",
    "        skill_reasoning = {}\n",
    "        missing_skills = []\n",
    "        total_score = 0\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            results = list(executor.map(lambda skill: self.analyze_skill(qa_chain, skill), skills))\n",
    "\n",
    "        for skill, score, reasoning in results:\n",
    "            skill_scores[skill] = score\n",
    "            skill_reasoning[skill] = reasoning\n",
    "            total_score += score\n",
    "            if score <= 5:\n",
    "                missing_skills.append(skill)\n",
    "\n",
    "        overall_score = int((total_score / (10 * len(skills))) * 100)\n",
    "        selected = overall_score >= self.cutoff_score\n",
    "\n",
    "        reasoning = \"Candidate evaluated based on explicit resume content using semantic similarity and clear numeric scoring.\"\n",
    "        strengths = [skill for skill, score in skill_scores.items() if score >= 7]\n",
    "        improvement_areas = missing_skills if not selected else []\n",
    "        \n",
    "\n",
    "        self.resume_strengths = strengths\n",
    "\n",
    "        return {\n",
    "            \"overall_score\": overall_score,\n",
    "            \"skill_scores\": skill_scores,\n",
    "            \"skill_reasoning\": skill_reasoning,\n",
    "            \"selected\": selected,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"missing_skills\": missing_skills,\n",
    "            \"strengths\": strengths,\n",
    "            \"improvement_areas\": improvement_areas\n",
    "        }\n",
    "\n",
    "    def analyze_resume(self, resume_file, role_requirements=None, custom_jd=None):\n",
    "        \"\"\"Analyze a resume against role requirements or a custom JD\"\"\"\n",
    "        self.resume_text = self.extract_text_from_file(resume_file)\n",
    "        \n",
    "       \n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.txt', mode='w', encoding='utf-8') as tmp:\n",
    "            tmp.write(self.resume_text)\n",
    "            self.resume_file_path = tmp.name\n",
    "     \n",
    "        self.rag_vectorstore = self.create_rag_vector_store(self.resume_text)\n",
    "        \n",
    "   \n",
    "        if custom_jd:\n",
    "            self.jd_text = self.extract_text_from_file(custom_jd)\n",
    "            self.extracted_skills = self.extract_skills_from_jd(self.jd_text)\n",
    "            \n",
    "        \n",
    "            self.analysis_result = self.semantic_skill_analysis(self.resume_text, self.extracted_skills)\n",
    "    \n",
    "        elif role_requirements:\n",
    "            self.extracted_skills = role_requirements\n",
    "            \n",
    " \n",
    "            self.analysis_result = self.semantic_skill_analysis(self.resume_text, role_requirements)\n",
    "            \n",
    "    \n",
    "        if self.analysis_result and \"missing_skills\" in self.analysis_result and self.analysis_result[\"missing_skills\"]:\n",
    "            self.analyze_resume_weaknesses()\n",
    "     \n",
    "            self.analysis_result[\"detailed_weaknesses\"] = self.resume_weaknesses\n",
    "        \n",
    "        return self.analysis_result\n",
    "\n",
    "\n",
    "    def ask_question(self, question,model):\n",
    "        \"\"\"Ask a question about the resume\"\"\"\n",
    "        if not self.rag_vectorstore or not self.resume_text:\n",
    "            return \"Please analyze a resume first.\"\n",
    "        \n",
    "        retriever = self.rag_vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 3}  \n",
    "        )\n",
    "        if self.llm_name==\"OpenAI\":\n",
    "            if model==None:\n",
    "                llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "            else :\n",
    "                llm = ChatOpenAI(model=model, api_key=self.api_key)\n",
    "\n",
    "        elif self.llm_name==\"Ollama\":\n",
    "            if model==None:\n",
    "                llm=ChatOllama(model=\"llama3.2\")\n",
    "            else:\n",
    "                llm=ChatOllama(model=model)\n",
    "\n",
    "        elif self.llm_name==\"Gemini\":\n",
    "            if model==None:\n",
    "                llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "            else:\n",
    "                llm=ChatGoogleGenerativeAI(model=model)\n",
    "        elif self.llm_name==\"Groq\":\n",
    "            if model==None:\n",
    "                llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "            else:\n",
    "                llm = ChatGroq(model=model)\n",
    "                \n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            # llm=ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key),\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",  \n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "        \n",
    "        response = qa_chain.run(question)\n",
    "        return response\n",
    "\n",
    "\n",
    "    def generate_interview_questions(self, question_types, difficulty, num_questions,model=None):\n",
    "        \"\"\"Generate interview questions based on the resume\"\"\"\n",
    "        if not self.resume_text or not self.extracted_skills:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "            if self.llm_name==\"OpenAI\":\n",
    "                if model==None:\n",
    "                    llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "                else :\n",
    "                    llm = ChatOpenAI(model=model, api_key=self.api_key)\n",
    "\n",
    "            elif self.llm_name==\"Ollama\":\n",
    "                if model==None:\n",
    "                    llm=ChatOllama(model=\"llama3.2\")\n",
    "                else:\n",
    "                    llm=ChatOllama(model=model)\n",
    "\n",
    "            elif self.llm_name==\"Gemini\":\n",
    "                if model==None:\n",
    "                    llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "                else:\n",
    "                    llm=ChatGoogleGenerativeAI(model=model)\n",
    "            elif self.llm_name==\"Groq\":\n",
    "                if model==None:\n",
    "                    llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "                else:\n",
    "                    llm = ChatGroq(model=model)\n",
    "                \n",
    "            \n",
    "        \n",
    "            context = f\"\"\"\n",
    "            Resume Content:\n",
    "            {self.resume_text[:2000]}...\n",
    "            \n",
    "            Skills to focus on: {', '.join(self.extracted_skills)}\n",
    "            \n",
    "            Strengths: {', '.join(self.analysis_result.get('strengths', []))}\n",
    "            \n",
    "            Areas for improvement: {', '.join(self.analysis_result.get('missing_skills', []))}\n",
    "            \"\"\"\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            Generate {num_questions} personalized {difficulty.lower()} level interview questions for this candidate \n",
    "            based on their resume and skills. Include only the following question types: {', '.join(question_types)}.\n",
    "            \n",
    "            For each question:\n",
    "            1. Clearly label the question type\n",
    "            2. Make the question specific to their background and skills\n",
    "            3. For coding questions, include a clear problem statement\n",
    "            \n",
    "            {context}\n",
    "            \n",
    "            Format the response as a list of tuples with the question type and the question itself.\n",
    "            Each tuple should be in the format: (\"Question Type\", \"Full Question Text\")\n",
    "            \"\"\"\n",
    "            \n",
    "            response = llm.invoke(prompt)\n",
    "            questions_text = response.content\n",
    "            \n",
    "      \n",
    "            questions = []\n",
    "            pattern = r'[(\"]([^\"]+)[\",)\\s]+[(\",\\s]+([^\"]+)[\")\\s]+'\n",
    "            matches = re.findall(pattern, questions_text, re.DOTALL)\n",
    "            \n",
    "            for match in matches:\n",
    "                if len(match) >= 2:\n",
    "                    question_type = match[0].strip()\n",
    "                    question = match[1].strip()\n",
    "                    \n",
    "     \n",
    "                    for requested_type in question_types:\n",
    "                        if requested_type.lower() in question_type.lower():\n",
    "                            questions.append((requested_type, question))\n",
    "                            break\n",
    "            \n",
    "\n",
    "            if not questions:\n",
    "                lines = questions_text.split('\\n')\n",
    "                current_type = None\n",
    "                current_question = \"\"\n",
    "                \n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if any(t.lower() in line.lower() for t in question_types) and not current_question:\n",
    "                        current_type = next((t for t in question_types if t.lower() in line.lower()), None)\n",
    "                        if \":\" in line:\n",
    "                            current_question = line.split(\":\", 1)[1].strip()\n",
    "                    elif current_type and line:\n",
    "                        current_question += \" \" + line\n",
    "                    elif current_type and current_question:\n",
    "                        questions.append((current_type, current_question))\n",
    "                        current_type = None\n",
    "                        current_question = \"\"\n",
    "\n",
    "            questions = questions[:num_questions]\n",
    "            \n",
    "            return questions\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating interview questions: {e}\")\n",
    "            return []\n",
    "        \n",
    "\n",
    "    def improve_resume(self, improvement_areas, target_role=\"\",model=None):\n",
    "        \"\"\"Generate suggestions to improve the resume\"\"\"\n",
    "        if not self.resume_text:\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "           \n",
    "            improvements = {}\n",
    "            \n",
    "  \n",
    "            for area in improvement_areas:\n",
    "           \n",
    "                if area == \"Skills Highlighting\" and self.resume_weaknesses:\n",
    "                    skill_improvements = {\n",
    "                        \"description\": \"Your resume needs to better highlight key skills that are important for the role.\",\n",
    "                        \"specific\": []\n",
    "                    }\n",
    "                 \n",
    "                    before_after_examples = {}\n",
    "                    \n",
    "                    for weakness in self.resume_weaknesses:\n",
    "                        skill_name = weakness.get(\"skill\", \"\")\n",
    "                        if \"suggestions\" in weakness and weakness[\"suggestions\"]:\n",
    "                            for suggestion in weakness[\"suggestions\"]:\n",
    "                                skill_improvements[\"specific\"].append(f\"**{skill_name}**: {suggestion}\")\n",
    "                        \n",
    "                        if \"example\" in weakness and weakness[\"example\"]:\n",
    "                       \n",
    "                            resume_chunks = self.resume_text.split('\\n\\n')\n",
    "                            relevant_chunk = \"\"\n",
    "                            \n",
    "                            \n",
    "                            for chunk in resume_chunks:\n",
    "                                if skill_name.lower() in chunk.lower() or \"experience\" in chunk.lower():\n",
    "                                    relevant_chunk = chunk\n",
    "                                    break\n",
    "                            \n",
    "                            if relevant_chunk:\n",
    "                                before_after_examples = {\n",
    "                                    \"before\": relevant_chunk.strip(),\n",
    "                                    \"after\": relevant_chunk.strip() + \"\\n‚Ä¢ \" + weakness[\"example\"]\n",
    "                                }\n",
    "                    \n",
    "                    if before_after_examples:\n",
    "                        skill_improvements[\"before_after\"] = before_after_examples\n",
    "                    \n",
    "                    improvements[\"Skills Highlighting\"] = skill_improvements\n",
    " \n",
    "            remaining_areas = [area for area in improvement_areas if area not in improvements]\n",
    "            \n",
    "            if remaining_areas:\n",
    "                \n",
    "                if self.llm_name==\"OpenAI\":\n",
    "                    if model==None:\n",
    "                        llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "                    else :\n",
    "                        llm = ChatOpenAI(model=model, api_key=self.api_key)\n",
    "\n",
    "                elif self.llm_name==\"Ollama\":\n",
    "                    if model==None:\n",
    "                        llm=ChatOllama(model=\"llama3.2\")\n",
    "                    else:\n",
    "                        llm=ChatOllama(model=model)\n",
    "\n",
    "                elif self.llm_name==\"Gemini\":\n",
    "                    if model==None:\n",
    "                        llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "                    else:\n",
    "                        llm=ChatGoogleGenerativeAI(model=model)\n",
    "                elif self.llm_name==\"Groq\":\n",
    "                    if model==None:\n",
    "                        llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "                    else:\n",
    "                        llm = ChatGroq(model=model)\n",
    "                    \n",
    "\n",
    "                # llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "                \n",
    "                # Create a context with resume analysis and weaknesses\n",
    "                weaknesses_text = \"\"\n",
    "                if self.resume_weaknesses:\n",
    "                    weaknesses_text = \"Resume Weaknesses:\\n\"\n",
    "                    for i, weakness in enumerate(self.resume_weaknesses):\n",
    "                        weaknesses_text += f\"{i+1}. {weakness['skill']}: {weakness['detail']}\\n\"\n",
    "                        if \"suggestions\" in weakness:\n",
    "                            for j, sugg in enumerate(weakness[\"suggestions\"]):\n",
    "                                weaknesses_text += f\"   - {sugg}\\n\"\n",
    "                \n",
    "                context = f\"\"\"\n",
    "                Resume Content:\n",
    "                {self.resume_text}\n",
    "                \n",
    "                Skills to focus on: {', '.join(self.extracted_skills)}\n",
    "                \n",
    "                Strengths: {', '.join(self.analysis_result.get('strengths', []))}\n",
    "                \n",
    "                Areas for improvement: {', '.join(self.analysis_result.get('missing_skills', []))}\n",
    "                \n",
    "                {weaknesses_text}\n",
    "                \n",
    "                Target role: {target_role if target_role else \"Not specified\"}\n",
    "                \"\"\"\n",
    "                \n",
    "                prompt = f\"\"\"\n",
    "                Provide detailed suggestions to improve this resume in the following areas: {', '.join(remaining_areas)}.\n",
    "                \n",
    "                {context}\n",
    "                \n",
    "                For each improvement area, provide:\n",
    "                1. A general description of what needs improvement\n",
    "                2. 3-5 specific actionable suggestions\n",
    "                3. Where relevant, provide a before/after example\n",
    "                \n",
    "                Format the response as a JSON object with improvement areas as keys, each containing:\n",
    "                - \"description\": general description\n",
    "                - \"specific\": list of specific suggestions\n",
    "                - \"before_after\": (where applicable) a dict with \"before\" and \"after\" examples\n",
    "                \n",
    "                Only include the requested improvement areas that aren't already covered.\n",
    "                Focus particularly on addressing the resume weaknesses identified.\n",
    "                \"\"\"\n",
    "                \n",
    "                response = llm.invoke(prompt)\n",
    "                \n",
    "                # Try to parse JSON from the response\n",
    "                ai_improvements = {}\n",
    "                \n",
    "                # Extract from markdown code blocks if present\n",
    "                json_match = re.search(r'```(?:json)?\\s*([\\s\\S]+?)\\s*```', response.content)\n",
    "                if json_match:\n",
    "                    try:\n",
    "                        ai_improvements = json.loads(json_match.group(1))\n",
    "                        # Merge with existing improvements\n",
    "                        improvements.update(ai_improvements)\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                \n",
    "                # If JSON parsing failed, create structured output manually\n",
    "                if not ai_improvements:\n",
    "                    sections = response.content.split(\"##\")\n",
    "                    \n",
    "                    for section in sections:\n",
    "                        if not section.strip():\n",
    "                            continue\n",
    "                            \n",
    "                        lines = section.strip().split(\"\\n\")\n",
    "                        area = None\n",
    "                        \n",
    "                        for line in lines:\n",
    "                            if not area and line.strip():\n",
    "                                area = line.strip()\n",
    "                                improvements[area] = {\n",
    "                                    \"description\": \"\",\n",
    "                                    \"specific\": []\n",
    "                                }\n",
    "                            elif area and \"specific\" in improvements[area]:\n",
    "                                if line.strip().startswith(\"- \"):\n",
    "                                    improvements[area][\"specific\"].append(line.strip()[2:])\n",
    "                                elif not improvements[area][\"description\"]:\n",
    "                                    improvements[area][\"description\"] += line.strip()\n",
    "            \n",
    "            # Ensure all requested areas are included\n",
    "            for area in improvement_areas:\n",
    "                if area not in improvements:\n",
    "                    improvements[area] = {\n",
    "                        \"description\": f\"Improvements needed in {area}\",\n",
    "                        \"specific\": [\"Review and enhance this section\"]\n",
    "                    }\n",
    "            \n",
    "            return improvements\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating resume improvements: {e}\")\n",
    "            return {area: {\"description\": \"Error generating suggestions\", \"specific\": []} for area in improvement_areas}\n",
    "    def get_improved_resume(self, target_role=\"\", highlight_skills=\"\",model=None):\n",
    "        \"\"\"Generate an improved version of the resume optimized for the job description\"\"\"\n",
    "        if not self.resume_text:\n",
    "            return \"Please upload and analyze a resume first.\"\n",
    "        \n",
    "        try:\n",
    "            # Parse highlight skills if provided\n",
    "            skills_to_highlight = []\n",
    "            if highlight_skills:\n",
    "\n",
    "                if len(highlight_skills) > 100: \n",
    "                    self.jd_text = highlight_skills\n",
    "                    try:\n",
    "                        parsed_skills = self.extract_skills_from_jd(highlight_skills)\n",
    "                        if parsed_skills:\n",
    "                            skills_to_highlight = parsed_skills\n",
    "                        else:\n",
    "                 \n",
    "                            skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "                    except:\n",
    "      \n",
    "                        skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "                else:\n",
    "                    skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "        \n",
    "            if not skills_to_highlight and self.analysis_result:\n",
    "\n",
    "                skills_to_highlight = self.analysis_result.get('missing_skills', [])\n",
    "  \n",
    "                skills_to_highlight.extend([\n",
    "                    skill for skill in self.analysis_result.get('strengths', [])\n",
    "                    if skill not in skills_to_highlight\n",
    "                ])\n",
    "\n",
    "                if self.extracted_skills:\n",
    "                    skills_to_highlight.extend([\n",
    "                        skill for skill in self.extracted_skills \n",
    "                        if skill not in skills_to_highlight\n",
    "                    ])\n",
    "            \n",
    "\n",
    "            weakness_context = \"\"\n",
    "            improvement_examples = \"\"\n",
    "            \n",
    "            if self.resume_weaknesses:\n",
    "                weakness_context = \"Address these specific weaknesses:\\n\"\n",
    "                \n",
    "                for weakness in self.resume_weaknesses:\n",
    "                    skill_name = weakness.get('skill', '')\n",
    "                    weakness_context += f\"- {skill_name}: {weakness.get('detail', '')}\\n\"\n",
    "                    \n",
    "           \n",
    "                    if 'suggestions' in weakness and weakness['suggestions']:\n",
    "                        weakness_context += \"  Suggested improvements:\\n\"\n",
    "                        for suggestion in weakness['suggestions']:\n",
    "                            weakness_context += f\"  * {suggestion}\\n\"\n",
    "    \n",
    "                    if 'example' in weakness and weakness['example']:\n",
    "                        improvement_examples += f\"For {skill_name}: {weakness['example']}\\n\\n\"\n",
    "            \n",
    "\n",
    "            if self.llm_name==\"OpenAI\":\n",
    "                if model==None:\n",
    "                    llm = ChatOpenAI(model=\"gpt-4o\", api_key=self.api_key)\n",
    "                else :\n",
    "                    llm = ChatOpenAI(model=model, api_key=self.api_key)\n",
    "\n",
    "            elif self.llm_name==\"Ollama\":\n",
    "                if model==None:\n",
    "                    llm=ChatOllama(model=\"llama3.2\")\n",
    "                else:\n",
    "                    llm=ChatOllama(model=model)\n",
    "\n",
    "            elif self.llm_name==\"Gemini\":\n",
    "                if model==None:\n",
    "                    llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "                else:\n",
    "                    llm=ChatGoogleGenerativeAI(model=model)\n",
    "            elif self.llm_name==\"Groq\":\n",
    "                if model==None:\n",
    "                    llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "                else:\n",
    "                    llm = ChatGroq(model=model)\n",
    "                \n",
    "\n",
    "\n",
    "            # llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7, api_key=self.api_key)\n",
    "            \n",
    "     \n",
    "            jd_context = \"\"\n",
    "            if self.jd_text:\n",
    "                jd_context = f\"Job Description:\\n{self.jd_text}\\n\\n\"\n",
    "            elif target_role:\n",
    "                jd_context = f\"Target Role: {target_role}\\n\\n\"\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            Rewrite and improve this resume to make it highly optimized for the target job.\n",
    "            \n",
    "            {jd_context}\n",
    "            Original Resume:\n",
    "            {self.resume_text}\n",
    "            \n",
    "            Skills to highlight (in order of priority): {', '.join(skills_to_highlight)}\n",
    "            \n",
    "            {weakness_context}\n",
    "            \n",
    "            Here are specific examples of content to add:\n",
    "            {improvement_examples}\n",
    "            \n",
    "            Please improve the resume by:\n",
    "            1. Adding strong, quantifiable achievements\n",
    "            2. Highlighting the specified skills strategically for ATS scanning\n",
    "            3. Addressing all the weakness areas identified with the specific suggestions provided\n",
    "            4. Incorporating the example improvements provided above\n",
    "            5. Structuring information in a clear, professional format\n",
    "            6. Using industry-standard terminology\n",
    "            7. Ensuring all relevant experience is properly emphasized\n",
    "            8. Adding measurable outcomes and achievements\n",
    "            \n",
    "            Return only the improved resume text without any additional explanations.\n",
    "            Format the resume in a modern, clean style with clear section headings.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = llm.invoke(prompt)\n",
    "            improved_resume = response.content.strip()\n",
    "       \n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.txt', mode='w', encoding='utf-8') as tmp:\n",
    "                tmp.write(improved_resume)\n",
    "                self.improved_resume_path = tmp.name\n",
    "            \n",
    "            return improved_resume\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating improved resume: {e}\")\n",
    "            return \"Error generating improved resume. Please try again.\"\n",
    "\n",
    "\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up temporary files\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'resume_file_path') and os.path.exists(self.resume_file_path):\n",
    "                os.unlink(self.resume_file_path)\n",
    "            \n",
    "            if hasattr(self, 'improved_resume_path') and os.path.exists(self.improved_resume_path):\n",
    "                os.unlink(self.improved_resume_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning up temporary files: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd596d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680ee24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-05-10T18:28:39.0646956Z', 'done': True, 'done_reason': 'stop', 'total_duration': 515138600, 'load_duration': 51889900, 'prompt_eval_count': 26, 'prompt_eval_duration': 5357800, 'eval_count': 8, 'eval_duration': 456547500, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b8466f92-4f91-4f03-93e6-6c302f25a1e0-0', usage_metadata={'input_tokens': 26, 'output_tokens': 8, 'total_tokens': 34})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatOllama(model=\"llama3.2\")\n",
    "llm.invoke(\"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
